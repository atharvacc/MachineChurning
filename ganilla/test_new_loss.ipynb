{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models.cycle_gan_model import CycleGANModel\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    def __init__(self):\n",
    "        self.input_nc = 3\n",
    "        self.gpu_ids = [0]\n",
    "        self.isTrain = True\n",
    "        self.checkpoints_dir = \"./saved_models\"\n",
    "        self.name = \"test_cyclegan/\"\n",
    "        self.resize_or_crop = \"resize_and_crop\"\n",
    "        self.lambda_identity = 0.5\n",
    "        self.lambda_A = 10.0\n",
    "        self.lambda_B = 10.0\n",
    "        self.output_nc = 3\n",
    "        self.ngf = 64\n",
    "        self.netG = 'resnet_fpn'\n",
    "        self.norm = 'instance'\n",
    "        self.no_dropout = False\n",
    "        self.init_type  = 'normal'\n",
    "        self.init_gain = 0.02\n",
    "        self.fpn_weights = [1.0, 1.0, 1.0, 1.0]\n",
    "        self.no_lsgan = \"store_true\"\n",
    "        self.ndf = 64\n",
    "        self.netD = 'basic'\n",
    "        self.n_layers_D = 3\n",
    "        self.pool_size = 50\n",
    "        self.lr = 0.0002\n",
    "        self.beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGANModel()\n",
    "o = opt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "model.initialize(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './kmeans_MUSE.sav'\n",
    "kmeans_HE = pickle.load(open(filename, 'rb'))\n",
    "img_HE = imread(\"./Stack0000_fake_B.png\")\n",
    "img_tensor = torch.Tensor(img_HE).reshape(-1,3)\n",
    "img_tensor = img_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([262144, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([73.7060, 58.7567, 65.5715], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([ 73.70598012,  58.75668164,  65.57153476]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'ast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3c60c22a12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ast'"
     ]
    }
   ],
   "source": [
    "c1 = torch.Tensor(kmeans_HE.cluster_centers_[0]).cuda()\n",
    "c2 = torch.Tensor(kmeans_HE.cluster_centers_[1]).cuda()\n",
    "d1 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor, c1),2),1)).reshape(1,512*512)\n",
    "d2 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor, c2),2),1)).reshape(1,512*512)\n",
    "t3 = torch.cat((d1,d2),0)\n",
    "out = torch.argmax(t3,0).reshape(512,512).ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([262144])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t3,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor.reshape(512,512,3), c1),2),1)).reshape(1,512*512)\n",
    "d2 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor, c2),2),1)).reshape(1,512*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.cat((d1,d2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.argmax(t3,0).reshape(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape is torch.Size([1, 3, 512, 512])'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Shape is torch.Size([1, 3, 512, 512])\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1224)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "loss(out.type(torch.FloatTensor) ,out1.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_HE(img):\n",
    "    \"\"\"\n",
    "    (FloatCudaTensor) transform_img: Takes in an image as an array and returns a segmentation mask for it given\n",
    "     = \n",
    "    \"\"\"\n",
    "    c1 = torch.Tensor([204.34305218, 173.81203058, 199.23028511]).cuda()\n",
    "    c2 = torch.Tensor([138.16460979, 111.94510225, 155.75621535]).cuda()\n",
    "    d1 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor, c1),2),1)).reshape(1,512*512)\n",
    "    d2 = torch.sqrt(torch.sum(torch.pow(torch.sub(img_tensor, c2),2),1)).reshape(1,512*512)\n",
    "    t3 = torch.cat((d1,d2),0)\n",
    "    out = torch.argmax(t3,0).reshape(512,512)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
