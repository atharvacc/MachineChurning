{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from torchvision.transforms.functional import crop\n",
    "import torch\n",
    "from PIL import Image\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_together(dir_name, row_count):\n",
    "    \"\"\"\n",
    "    stitch together the predictions made by the model\n",
    "    \n",
    "    Args:\n",
    "         dir_name: directory containg all of the images\n",
    "         param row_count: number of images in a row\n",
    "    \n",
    "    Returns:\n",
    "            stitched_img: image where everything is stitched together\n",
    "    \"\"\"\n",
    "\n",
    "    image_names = listdir(dir_name)\n",
    "    image_names.sort()\n",
    "    stackedImgs = []\n",
    "    curStack = []\n",
    "    cur_row = 1\n",
    "    for img_name in image_names:\n",
    "        img = imread(dir_name + img_name)\n",
    "        curStack.append(img)\n",
    "        if(cur_row % 10 == 0):\n",
    "            hstacked = np.hstack(curStack)\n",
    "            stackedImgs.append(hstacked)\n",
    "            curStack=[]\n",
    "            cur_row = 0\n",
    "        cur_row= cur_row + 1\n",
    "    out = np.vstack(stackedImgs)\n",
    "    return out\n",
    "\n",
    "def generate_overlapping_images(img, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Generate crops from image of size window_size by window_size. Crops can be overlapping by \n",
    "    setting the step_size\n",
    "    \n",
    "    Args:\n",
    "        img: image as a numpy array\n",
    "        window_size: Size of the crops that are generated\n",
    "        step_size: step size for the window\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    m,n,_ = img.shape\n",
    "    x = 0 \n",
    "    y = 0\n",
    "    pil_img = Image.fromarray(img)\n",
    "    max_x = m - window_size\n",
    "    max_y = n - window_size\n",
    "    imgs = []\n",
    "    count = 0\n",
    "    print(\"Max_x is {}\".format(max_x))\n",
    "    print(\"Max_y is {}\".format(max_y))\n",
    "    while(x<=max_x):\n",
    "        while(y<=max_y):\n",
    "            crop_img = crop(pil_img, x, y, window_size, window_size)\n",
    "            crop_img.save(\"overlap/Stack_{}.png\".format(str(count).zfill(4)) )\n",
    "            count=count+1\n",
    "            y = y + step_size\n",
    "        y = 0 \n",
    "        x = x + step_size\n",
    "    return imgs\n",
    "            \n",
    "def avg_blend(img1,img2):\n",
    "    return ((img1+img2)/2).astype(np.uint8)\n",
    "\n",
    "def merge_horiz(left_img, right_img, step_size):\n",
    "    \"\"\"\n",
    "    merge the two images using step size\n",
    "    \n",
    "    Args:\n",
    "        left_img: the image on the left\n",
    "        right_img: Image on the right\n",
    "        Step_size: Step size used while generating the image\n",
    "    Returns:\n",
    "        combined_img: Image containing the combination of the two where the overlapping region\n",
    "                      is merged using a blending function\n",
    "    \"\"\"\n",
    "    m,n,_ = left_img.shape\n",
    "    m1,n1,_ = right_img.shape\n",
    "    left = left_img[:, 0:n-step_size,:]\n",
    "    combine_left = left_img[:,n-step_size:,:].astype('float')\n",
    "    combine_right = right_img[:, 0:n1-step_size,:].astype('float')\n",
    "    right = right_img[:,n1-step_size:,:]\n",
    "    combine = avg_blend(combine_left, combine_right)\n",
    "    return  np.hstack((left, combine, right))\n",
    "\n",
    "def merge_vert(top_img, bot_img, step_size):\n",
    "    \"\"\"\n",
    "    merge the two images using step size\n",
    "    \n",
    "    Args:\n",
    "        left_img: the image on the left\n",
    "        right_img: Image on the right\n",
    "        Step_size: Step size used while generating the image\n",
    "    Returns:\n",
    "        combined_img: Image containing the combination of the two where the overlapping region\n",
    "                      is merged using a blending function\n",
    "    \"\"\"\n",
    "    m,n,_ = top_img.shape\n",
    "    top = top_img[0:m-step_size,:,:]\n",
    "    combine_top = top_img[m-step_size:,:,:].astype('float')\n",
    "    combine_bot = bot_img[0:step_size,:,:].astype('float')\n",
    "    bot = bot_img[step_size:,:,:]\n",
    "    combine = avg_blend(combine_top, combine_bot)\n",
    "    return  np.vstack((top, combine, bot))\n",
    "\n",
    "def gen_merged_horiz(img_list, step_size):\n",
    "    \"\"\"\n",
    "    takes a list of images and merges them based on step_size\n",
    "    \n",
    "    Args:\n",
    "        img_list: list containing all of the images\n",
    "        step_size: the step size to be used \n",
    "    Returns:\n",
    "        img: The merged image\n",
    "    \"\"\"\n",
    "    \n",
    "    img = img_list[0]\n",
    "    new_list = img_list[1:]\n",
    "    for img_r in new_list:\n",
    "        img = merge_horiz(img, img_r, step_size)\n",
    "    return img\n",
    "\n",
    "def gen_merged_vert(img_list, step_size):\n",
    "    \"\"\"\n",
    "    takes a list of images and merges them based on step_size\n",
    "    \n",
    "    Args:\n",
    "        img_list: list containing all of the images\n",
    "        step_size: the step size to be used \n",
    "    Returns:\n",
    "        img: The merged image\n",
    "    \"\"\"\n",
    "    \n",
    "    img = img_list[0]\n",
    "    new_list = img_list[1:]\n",
    "    for img_t in new_list:\n",
    "        img = merge_vert(img, img_t, step_size)\n",
    "    return img\n",
    "\n",
    "def stitch_blend(dir_name, row_count,step_size):\n",
    "    \"\"\"\n",
    "    stitch together the predictions made by the model\n",
    "    \n",
    "    Args:\n",
    "         dir_name: directory containg all of the images\n",
    "         param row_count: number of images in a row\n",
    "    \n",
    "    Returns:\n",
    "            out: image where everything is stitched together\n",
    "    \"\"\"\n",
    "\n",
    "    image_names = listdir(dir_name)\n",
    "    image_names.sort()\n",
    "    stackedImgs = []\n",
    "    curStack = []\n",
    "    cur_row = 1\n",
    "    for img_name in image_names:\n",
    "        img = imread(dir_name + img_name)\n",
    "        curStack.append(img)\n",
    "        if(cur_row % row_count == 0):\n",
    "            hstacked = gen_merged_horiz(curStack, step_size)\n",
    "            stackedImgs.append(hstacked)\n",
    "            curStack=[]\n",
    "            cur_row = 0\n",
    "        cur_row= cur_row + 1\n",
    "    out = gen_merged_vert(stackedImgs, step_size)\n",
    "    return out\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = stitch_together('./real_A/', 10)\n",
    "ov = stitch_blend('./overlap/', 19,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
